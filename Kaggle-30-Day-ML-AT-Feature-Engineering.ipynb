{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is for the 30 Days of Machine Learning contest on Kaggle.\n",
    "\n",
    "#### This notebook was created by following Abhishek Thakur's YouTube video tutorial: \n",
    "https://www.youtube.com/playlist?list=PL98nY_tJQXZnP-k3qCDd1hljVSciDV9_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train_folds.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")\n",
    "sample_submission = pd.read_csv(\"data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7243571395158775\n",
      "1 0.7241138992076518\n",
      "2 0.7264791794845865\n",
      "3 0.7268358534164948\n",
      "4 0.7251732609696491\n",
      "0.725391866518852 0.0010971778754004847\n"
     ]
    }
   ],
   "source": [
    "useful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\n",
    "object_cols = [col for col in useful_features if 'cat' in col]\n",
    "numerical_cols = [col for col in useful_features if col.startswith(\"cont\")]\n",
    "df_test = df_test[useful_features]\n",
    "\n",
    "final_predictions = []\n",
    "scores = []\n",
    "for fold in range(5):\n",
    "    xtrain = df[df.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    xtest = df_test.copy()\n",
    "    \n",
    "    ytrain = xtrain.target\n",
    "    yvalid = xvalid.target\n",
    "    \n",
    "    xtrain = xtrain[useful_features]\n",
    "    xvalid = xvalid[useful_features]\n",
    "    \n",
    "   \n",
    "    ordinal_encoder = preprocessing.OrdinalEncoder()\n",
    "    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n",
    "    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n",
    "    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n",
    "    \n",
    "    scalar = preprocessing.StandardScaler()\n",
    "    xtrain[numerical_cols] = scalar.fit_transform(xtrain[numerical_cols])\n",
    "    xvalid[numerical_cols] = scalar.transform(xvalid[numerical_cols])\n",
    "    xtest[numerical_cols] = scalar.transform(xtest[numerical_cols])\n",
    "   \n",
    "    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor=\"gpu_predictor\")\n",
    "    model.fit(xtrain, ytrain)\n",
    "    preds_valid = model.predict(xvalid)\n",
    "    test_preds = model.predict(xtest)\n",
    "    final_predictions.append(test_preds)\n",
    "    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n",
    "    print(fold, rmse)\n",
    "    scores.append(rmse)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.724586701292055\n",
      "1 0.7238448854613491\n",
      "2 0.7262243222545884\n",
      "3 0.726720379332222\n",
      "4 0.7255240155821197\n",
      "0.7253800607844668 0.0010503463028987453\n"
     ]
    }
   ],
   "source": [
    "# log transformation\n",
    "useful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\n",
    "object_cols = [col for col in useful_features if 'cat' in col]\n",
    "numerical_cols = [col for col in useful_features if col.startswith(\"cont\")]\n",
    "df_test = df_test[useful_features]\n",
    "\n",
    "for col in numerical_cols:\n",
    "    df[col] = np.log1p(df[col])\n",
    "    df_test[col] = np.log1p(df_test[col])\n",
    "\n",
    "final_predictions = []\n",
    "scores = []\n",
    "for fold in range(5):\n",
    "    xtrain = df[df.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    xtest = df_test.copy()\n",
    "    \n",
    "    ytrain = xtrain.target\n",
    "    yvalid = xvalid.target\n",
    "    \n",
    "    xtrain = xtrain[useful_features]\n",
    "    xvalid = xvalid[useful_features]\n",
    "    \n",
    "   \n",
    "    ordinal_encoder = preprocessing.OrdinalEncoder()\n",
    "    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n",
    "    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n",
    "    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n",
    "    \n",
    "\n",
    "   \n",
    "    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor=\"gpu_predictor\")\n",
    "    model.fit(xtrain, ytrain)\n",
    "    preds_valid = model.predict(xvalid)\n",
    "    test_preds = model.predict(xtest)\n",
    "    final_predictions.append(test_preds)\n",
    "    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n",
    "    print(fold, rmse)\n",
    "    scores.append(rmse)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7291687225559282\n",
      "1 0.7284671111716613\n",
      "2 0.7305888523262705\n",
      "3 0.7295904737805866\n",
      "4 0.7297305483962165\n",
      "0.7295091416461326 0.0006961499385310329\n"
     ]
    }
   ],
   "source": [
    "# polynomial features\n",
    "df = pd.read_csv(\"data/train_folds.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")\n",
    "sample_submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "\n",
    "useful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\n",
    "object_cols = [col for col in useful_features if 'cat' in col]\n",
    "numerical_cols = [col for col in useful_features if col.startswith(\"cont\")]\n",
    "df_test = df_test[useful_features]\n",
    "\n",
    "poly = preprocessing.PolynomialFeatures(degree=3, interaction_only=True, include_bias=False)\n",
    "train_poly = poly.fit_transform(df[numerical_cols])\n",
    "test_poly = poly.fit_transform(df_test[numerical_cols])\n",
    "\n",
    "df_poly = pd.DataFrame(train_poly, columns=[f\"poly_{i}\" for i in range(train_poly.shape[1])])\n",
    "df_test_poly = pd.DataFrame(test_poly, columns=[f\"poly_{i}\" for i in range(test_poly.shape[1])])\n",
    "\n",
    "\n",
    "df = pd.concat([df, df_poly], axis=1)\n",
    "df_test = pd.concat([df_test, df_test_poly], axis=1)\n",
    "\n",
    "\n",
    "useful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\n",
    "object_cols = [col for col in useful_features if 'cat' in col]\n",
    "df_test = df_test[useful_features]\n",
    "\n",
    "final_predictions = []\n",
    "scores = []\n",
    "for fold in range(5):\n",
    "    xtrain = df[df.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    xtest = df_test.copy()\n",
    "    \n",
    "    ytrain = xtrain.target\n",
    "    yvalid = xvalid.target\n",
    "    \n",
    "    xtrain = xtrain[useful_features]\n",
    "    xvalid = xvalid[useful_features]\n",
    "    \n",
    "   \n",
    "    ordinal_encoder = preprocessing.OrdinalEncoder()\n",
    "    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n",
    "    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n",
    "    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n",
    "    \n",
    "\n",
    "   \n",
    "    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor=\"gpu_predictor\")\n",
    "    model.fit(xtrain, ytrain)\n",
    "    preds_valid = model.predict(xvalid)\n",
    "    test_preds = model.predict(xtest)\n",
    "    final_predictions.append(test_preds)\n",
    "    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n",
    "    print(fold, rmse)\n",
    "    scores.append(rmse)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binning the numerical features\n",
    "# pd.cut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float, bool or categorical.  When\n                categorical type is supplied, DMatrix parameter\n                `enable_categorical` must be set to `True`.cat0, cat1, cat2, cat3, cat4, cat5, cat6, cat7, cat8, cat9",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-fde3a7443942>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtree_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gpu_hist'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpu_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"gpu_predictor\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[0mpreds_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxvalid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mtest_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m    723\u001b[0m             \u001b[0meval_group\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m             \u001b[0meval_qid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 725\u001b[1;33m             \u001b[0mcreate_dmatrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnthread\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    726\u001b[0m         )\n\u001b[0;32m    727\u001b[0m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_xgb_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36m_wrap_evaluation_matrices\u001b[1;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, label_transform)\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[0mbase_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_margin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m         \u001b[0mfeature_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m         \u001b[0mmissing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m     )\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    723\u001b[0m             \u001b[0meval_group\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m             \u001b[0meval_qid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 725\u001b[1;33m             \u001b[0mcreate_dmatrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnthread\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    726\u001b[0m         )\n\u001b[0;32m    727\u001b[0m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_xgb_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mfeature_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m             \u001b[0mfeature_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0menable_categorical\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menable_categorical\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         )\n\u001b[0;32m    549\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\xgboost\\data.py\u001b[0m in \u001b[0;36mdispatch_data_backend\u001b[1;34m(data, missing, threads, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[0;32m    572\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_pandas_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m         return _from_pandas_df(data, enable_categorical, missing, threads,\n\u001b[1;32m--> 574\u001b[1;33m                                feature_names, feature_types)\n\u001b[0m\u001b[0;32m    575\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_pandas_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m         return _from_pandas_series(data, missing, threads, feature_names,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\xgboost\\data.py\u001b[0m in \u001b[0;36m_from_pandas_df\u001b[1;34m(data, enable_categorical, missing, nthread, feature_names, feature_types)\u001b[0m\n\u001b[0;32m    257\u001b[0m                     feature_names, feature_types):\n\u001b[0;32m    258\u001b[0m     data, feature_names, feature_types = _transform_pandas_df(\n\u001b[1;32m--> 259\u001b[1;33m         data, enable_categorical, feature_names, feature_types)\n\u001b[0m\u001b[0;32m    260\u001b[0m     return _from_numpy_array(data, missing, nthread, feature_names,\n\u001b[0;32m    261\u001b[0m                              feature_types)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\xgboost\\data.py\u001b[0m in \u001b[0;36m_transform_pandas_df\u001b[1;34m(data, enable_categorical, feature_names, feature_types, meta, meta_type)\u001b[0m\n\u001b[0;32m    221\u001b[0m                 \u001b[0mcategorical\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0msupplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDMatrix\u001b[0m \u001b[0mparameter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 `enable_categorical` must be set to `True`.\"\"\"\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbad_fields\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmeta\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float, bool or categorical.  When\n                categorical type is supplied, DMatrix parameter\n                `enable_categorical` must be set to `True`.cat0, cat1, cat2, cat3, cat4, cat5, cat6, cat7, cat8, cat9"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train_folds.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")\n",
    "sample_submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "\n",
    "useful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\n",
    "object_cols = [col for col in useful_features if 'cat' in col]\n",
    "numerical_cols = [col for col in useful_features if col.startswith(\"cont\")]\n",
    "df_test = df_test[useful_features]\n",
    "\n",
    "final_predictions = []\n",
    "scores = []\n",
    "for fold in range(5):\n",
    "    xtrain = df[df.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    xtest = df_test.copy()\n",
    "    \n",
    "    ytrain = xtrain.target\n",
    "    yvalid = xvalid.target\n",
    "    \n",
    "    xtrain = xtrain[useful_features]\n",
    "    xvalid = xvalid[useful_features]\n",
    "    \n",
    "    ohe = preprocessing.OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n",
    "    xtrain_ohe = ohe.fit_transform(xtrain[object_cols])\n",
    "    xvalid_ohe = ohe.transform(xvalid[object_cols])\n",
    "    xtest_ohe = ohe.transform(xtest[object_cols])\n",
    "    \n",
    "    xtrain_ohe = pd.DataFrame(xtrain_ohe, columns=[f\"ohe_{i}\" for i in range(xtrain_ohe.shape[1])])\n",
    "    xvalid_ohe = pd.DataFrame(xvalid_ohe, columns=[f\"ohe_{i}\" for i in range(xvalid_ohe.shape[1])])\n",
    "    xtest_ohe = pd.DataFrame(xtest_ohe, columns=[f\"ohe_{i}\" for i in range(xtest_ohe.shape[1])])\n",
    "\n",
    "    xtrain = pd.concat([xtrain, xtrain_ohe], axis=1)\n",
    "    xvalid = pd.concat([xvalid, xvalid_ohe], axis=1)\n",
    "    xtest = pd.concat([xtest, xtest_ohe], axis=1)\n",
    "    \n",
    "    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor=\"gpu_predictor\")\n",
    "    model.fit(xtrain, ytrain)\n",
    "    preds_valid = model.predict(xvalid)\n",
    "    test_preds = model.predict(xtest)\n",
    "    final_predictions.append(test_preds)\n",
    "    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n",
    "    print(fold, rmse)\n",
    "    scores.append(rmse)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding of categorical variables + standardization of ohe & numerical"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
